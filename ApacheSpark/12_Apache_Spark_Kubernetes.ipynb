{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "9198e8a0-76bd-4221-8b03-9965fee84de6"
            },
            "source": [
                "# Laboratorio de Apache Spark en Kubernetes\n",
                "\n",
                "##   \n",
                "\n",
                "## Objetivos de Aprendizaje\n",
                "\n",
                "En este laboratorio, usted:\n",
                "\n",
                "- Creará un Pod de Kubernetes - un conjunto de contenedores que se ejecutan dentro de Kubernetes - aquí, que contiene Apache Spark que utilizamos para enviar trabajos a Kubernetes\n",
                "- Enviará trabajos de Apache Spark a Kubernetes\n",
                "\n",
                "## Resumen\n",
                "\n",
                "Bienvenido al laboratorio sobre cómo enviar aplicaciones de Apache Spark a un clúster de Kubernetes. Este ejercicio es sencillo gracias al nuevo programador nativo de Kubernetes que se ha añadido a Spark recientemente.\n",
                "\n",
                "Kubernetes es un orquestador de contenedores que permite programar millones de contenedores “docker” en enormes clústeres de computación que contienen miles de nodos de computación. Originalmente inventado y de código abierto por Google, Kubernetes se convirtió en el estándar de facto para el desarrollo y despliegue de aplicaciones nativas de la nube dentro y fuera de IBM. Con RedHat OpenShift, IBM es el líder en Kubernetes de nube híbrida y se encuentra entre las tres principales empresas que contribuyen a la base de código abierto de Kubernetes."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "21a4461e-4dbd-422f-9388-cd2ed5979ab6"
            },
            "source": [
                "# Requisitos Previos\n",
                "\n",
                "Nota: Si estás ejecutando este laboratorio dentro del entorno de Skillsnetwort Lab, todos los requisitos previos ya están instalados para ti.\n",
                "\n",
                "Los únicos requisitos previos para este laboratorio son:\n",
                "\n",
                "- Una instalación de _docker_ en funcionamiento\n",
                "- Una instalación de _kubernetes_ en funcionamiento\n",
                "- La herramienta de línea de comandos _git_"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "a4de6933-8e9a-45ef-82bb-f1d8ac88c272"
            },
            "source": [
                "# Configuración\n",
                "\n",
                "1. En el lado derecho de estas instrucciones verás el IDE Theia. Selecciona la pestaña _Lab_. En la barra de menú selecciona _Terminal\\>Nuevo Terminal_.\n",
                "\n",
                "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/images/NewTerminal.png)\n",
                "\n",
                "2. Por favor, ingresa el siguiente comando en el terminal para obtener el código más reciente.\n",
                "\n",
                "```bash\n",
                "git clone https://github.com/ibm-developer-skills-network/fgskh-new_horizons.git\n",
                "\n",
                "```\n",
                "\n",
                "3. Cambia el directorio al código descargado.\n",
                "\n",
                "```bash\n",
                "cd fgskh-new_horizons\n",
                "\n",
                "```\n",
                "\n",
                "4. Agrega un alias a `kubectl`. Esto te ayudará a escribir solo `k` en lugar de `kubectl`.\n",
                "\n",
                "```bash\n",
                "alias k='kubectl'\n",
                "\n",
                "```\n",
                "\n",
                "5. Guarda el espacio de nombres actual en una variable de entorno que se utilizará más tarde.\n",
                "\n",
                "```bash\n",
                "my_namespace=$(kubectl config view --minify -o jsonpath='{..namespace}')\n",
                "\n",
                "```"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "fa2a11cb-fd0d-41f8-b20e-4e7147ff2aec"
            },
            "source": [
                "# Desplegar el Pod de Apache Spark en Kubernetes\n",
                "\n",
                "1. Instalar el POD de Apache Spark\n",
                "\n",
                "```bash\n",
                "k apply -f spark/pod_spark.yaml\n",
                "```\n",
                "\n",
                "2. Ahora es el momento de verificar el estado del Pod ejecutando el siguiente comando.\n",
                "\n",
                "```bash\n",
                "k get po\n",
                "```\n",
                "\n",
                "Si ves la siguiente salida, significa que el Pod aún no está disponible y necesitas esperar un poco.\n",
                "\n",
                "```bash\n",
                "NAME   READY   STATUS              RESTARTS   AGE\n",
                "spark  0/2     ContainerCreating   0          29s\n",
                "```\n",
                "\n",
                "3. Espera unos segundos y emite el comando nuevamente después de un tiempo.\n",
                "\n",
                "```bash\n",
                "k get po\n",
                "```\n",
                "\n",
                "> Por favor, repite el paso 2 hasta que tengas un `STATUS` que refleje que está `Running`.\n",
                "\n",
                "4. Deberías ver una salida como la que se muestra a continuación. El atributo `AGE` puede ser diferente, dependiendo de cuánto tiempo te tomó hacerlo funcionar.\n",
                "\n",
                "```bash\n",
                "NAME  READY   STATUS    RESTARTS   AGE\n",
                "spark 2/2     Running   0          10m\n",
                "```\n",
                "\n",
                "> En caso de que veas el siguiente estado, necesitas eliminar el pod y comenzar de nuevo más tarde, ya que esto suele ocurrir cuando el registro de imágenes es poco fiable o está fuera de línea.\n",
                "\n",
                "```bash\n",
                "NAME   READY   STATUS              RESTARTS   AGE\n",
                "spark  0/2     ImagePullBackOff    0          29s\n",
                "```\n",
                "\n",
                "5. Solo en este caso, por favor elimina el pod:\n",
                "\n",
                "```bash\n",
                "k delete po spark\n",
                "```\n",
                "\n",
                "Entonces comienza de nuevo:\n",
                "\n",
                "```bash\n",
                "k apply -f spark/pod_spark.yaml\n",
                "```\n",
                "\n",
                "De nuevo, verifica el estado regularmente:\n",
                "\n",
                "```bash\n",
                "k get po\n",
                "```\n",
                "\n",
                "Tenga en cuenta que este Pod se llama _spark_ y contiene dos contenedores _(2/2)_, ambos en estado _Running_. También tenga en cuenta que Kubernetes _RESTARTS_ automáticamente los pods fallidos; esto no ha sucedido aquí hasta ahora. Probablemente porque la _AGE_ de este pod es de solo 10 minutos."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "4cbd547e-54ef-4f67-b845-cff266922e8f"
            },
            "source": [
                "# Enviar trabajos de Apache Spark a Kubernetes\n",
                "\n",
                "Ahora es el momento de ejecutar un comando dentro del contenedor _spark_ de este Pod. Se le indica al comando _exec_ que proporcione acceso al contenedor llamado _spark_ (-c). Con _–_ ejecutamos un comando, en este ejemplo simplemente mostramos un mensaje.\n",
                "\n",
                "```bash\n",
                "k exec spark -c spark  -- echo \"Hello from inside the container\"\n",
                "```\n",
                "\n",
                "Acabas de ejecutar un comando en el contenedor _spark_ que reside en el pod _spark_ dentro de Kubernetes. Usaremos este contenedor para enviar aplicaciones Spark al clúster de Kubernetes. Este contenedor se basa en una imagen con la distribución de Apache Spark y el comando _kubectl_ preinstalado.\n",
                "\n",
                "Si estás interesado, puedes echar un vistazo al [Dockerfile](https://github.com/romeokienzler/new_horizons/blob/main/spark/Dockerfile) para entender qué hay realmente dentro.\n",
                "\n",
                "También puedes consultar el [pod.yaml](https://github.com/romeokienzler/new_horizons/blob/main/spark/pod_spark.yaml). Notarás que contiene dos contenedores. Uno es Apache Spark, y el otro proporciona un Proxy de Kubernetes - un contenedor llamado side car - que permite interactuar con el clúster de Kubernetes desde dentro de un Pod.\n",
                "\n",
                "Dentro del contenedor puedes usar el comando _spark-submit_ que utiliza el nuevo programador nativo de Kubernetes que se ha añadido recientemente a Spark.\n",
                "\n",
                "El siguiente comando envía la aplicación de muestra _SparkPi_ al clúster. SparkPi calcula Pi y cuantas más iteraciones ejecutes, más preciso se vuelve:\n",
                "\n",
                "```bash\n",
                "k exec spark -c spark -- ./bin/spark-submit \\\n",
                "--master k8s://http://127.0.0.1:8001 \\\n",
                "--deploy-mode cluster \\\n",
                "--name spark-pi \\\n",
                "--class org.apache.spark.examples.SparkPi \\\n",
                "--conf spark.executor.instances=1 \\\n",
                "--conf spark.kubernetes.container.image=romeokienzler/spark-py:3.1.2 \\\n",
                "--conf spark.kubernetes.executor.request.cores=0.2 \\\n",
                "--conf spark.kubernetes.executor.limit.cores=0.3 \\\n",
                "--conf spark.kubernetes.driver.request.cores=0.2 \\\n",
                "--conf spark.kubernetes.driver.limit.cores=0.3 \\\n",
                "--conf spark.driver.memory=512m \\\n",
                "--conf spark.kubernetes.namespace=${my_namespace} \\\n",
                "local:///opt/spark/examples/jars/spark-examples_2.12-3.1.2.jar \\\n",
                "10\n",
                "```\n",
                "\n",
                "Deberías ver una salida como la siguiente, por favor ignora las ADVERTENCIAS. A menos que no veas ERRORES, todo está bien:\n",
                "\n",
                "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/images/kube_lab_spark_submit_output.png)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "56f9ed5f-f84b-4008-a62d-2bd05abaf3df"
            },
            "source": [
                "# Entendiendo el comando spark-submit\n",
                "\n",
                "Así que veamos qué está sucediendo aquí:\n",
                "\n",
                "- _./bin/spark-submit_ es el comando para enviar aplicaciones a un clúster de Apache Spark\n",
                "- _–master k8s://[http://127.0.0.1:8001](http://127.0.0.1:8001/)_ es la dirección del servidor API de Kubernetes - la forma en que _kubectl_ pero también el programador nativo de Kubernetes de Apache Spark interactúa con el clúster de Kubernetes\n",
                "- _–name spark-pi_ proporciona un nombre para el trabajo y los Pods subsiguientes creados por el programador nativo de Kubernetes de Apache Spark se prefijan con ese nombre\n",
                "- _–class org.apache.spark.examples.SparkPi_ proporciona el nombre canónico de la aplicación Spark que se va a ejecutar (nombre del paquete Java y nombre de la clase)\n",
                "- _–conf spark.executor.instances=1_ le dice al programador nativo de Kubernetes de Apache Spark cuántos Pods debe crear para paralelizar la aplicación. Tenga en cuenta que en este clúster de desarrollo de un solo nodo, aumentar este número no tiene sentido (además de agregar sobrecarga por paralelización)\n",
                "- _–conf spark.kubernetes.container.image=romeokienzler/spark-py:3.1.2_ le dice al programador nativo de Kubernetes de Apache Spark qué imagen de contenedor debe usar para crear los Pods del driver y del executor. Esta imagen se puede construir de forma personalizada utilizando los Dockerfiles proporcionados en _kubernetes/dockerfiles/spark/_ y _bin/docker-image-tool.sh_ en la distribución de Apache Spark\n",
                "- _–conf spark.kubernetes.executor.limit.cores=0.3_ le dice al programador nativo de Kubernetes de Apache Spark que establezca el límite de núcleos de CPU para usar solo 0.3 núcleo por Pod executor\n",
                "- _–conf spark.kubernetes.driver.limit.cores=0.3_ le dice al programador nativo de Kubernetes de Apache Spark que establezca el límite de núcleos de CPU para usar solo 0.3 núcleo para el Pod del driver\n",
                "- _–conf spark.driver.memory=512m_ le dice al programador nativo de Kubernetes de Apache Spark que establezca el límite de memoria para usar solo 512MB para el Pod del driver\n",
                "- _–conf spark.kubernetes.namespace=${my\\_namespace}_ le dice al programador nativo de Kubernetes de Apache Spark que establezca el namespace a la variable de entorno _my\\_namespace_ que configuramos antes.\n",
                "- _local:///opt/spark/examples/jars/spark-examples\\_2.12-3.1.2.jar_ indica el archivo _jar_ que contiene la aplicación. Tenga en cuenta que el prefijo _local://_ se refiere a una ruta dentro de las imágenes de contenedor proporcionadas por la opción _spark.kubernetes.container.image_. Dado que estamos utilizando un _jar_ proporcionado por la distribución de Apache Spark, esto no es un problema; de lo contrario, la opción _spark.kubernetes.file.upload.path_ debe configurarse y debe configurarse un subsistema de almacenamiento apropiado, como se describe en la [documentación](https://spark.apache.org/docs/latest/running-on-kubernetes.html#running-spark-on-kubernetes)\n",
                "- _10_ le dice a la aplicación que se ejecute durante _10_ iteraciones, luego muestre el valor calculado de _Pi_\n",
                "\n",
                "Por favor, consulte la [documentación](https://spark.apache.org/docs/latest/running-on-kubernetes.html#configuration) para obtener una lista completa de los parámetros disponibles."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "59dd1ffe-55fd-4740-a0d7-a79407b4fd31"
            },
            "source": [
                "# Monitorear la aplicación Spark en una terminal paralela\n",
                "\n",
                "Una vez que se ejecute este comando, puedes _abrir una segunda ventana de terminal_ dentro de Theia y emitir el siguiente comando:\n",
                "\n",
                "> **Nota:** Para ver al menos un ejecutor, ejecuta el comando mencionado a continuación mientras la otra terminal aún está ejecutando el comando spark-submit.\n",
                "\n",
                "```bash\n",
                "kubectl get po\n",
                "```\n",
                "\n",
                "Esto te mostrará los Pods adicionales que están siendo creados por el programador nativo de Kubernetes de Apache Spark: un controlador y al menos un ejecutor. Ten en cuenta que con solo un ejecutor, el controlador puede ejecutar el ejecutor dentro de su propio pod. Aquí hay un ejemplo cuando se utiliza un ejecutor que se ejecuta por separado del pod del controlador (los IDs exactos se reemplazan por X y Y para facilitar la lectura):\n",
                "\n",
                "```bash\n",
                "NAME              READY STATUS    RESTARTS AGE\n",
                "spark             2/2   Running   0        28m\n",
                "spark-pi-X-exec-1 1/1   Running   0        33s\n",
                "spark-pi-X-driver 1/1   Running   0        44s\n",
                "spark-pi-Y-driver 0/1   Completed 0        12m\n",
                "```\n",
                "\n",
                "Puedes ver que el Pod _spark-pi-Y-driver_ está en estado _Completed_, de una ejecución de un solo ejecutor hace doce minutos y que hay un controlador y tres ejecutores actualmente en ejecución para el trabajo _spark-pi-X- .._.\n",
                "\n",
                "Para verificar el tiempo transcurrido del trabajo, simplemente ejecuta (necesitas reemplazar el nombre del Pod, por supuesto, con el que está en tu sistema):\n",
                "\n",
                "<span data-darkreader-inline-color=\"\" style=\"scrollbar-color: rgb(69, 74, 77) rgb(32, 35, 36); padding: 0px; margin: 0px; box-sizing: border-box; color: red; --darkreader-inline-color: #ff1a1a;\">Por favor, asegúrate de ejecutar el siguiente código en la nueva ventana de terminal que te permite ejecutar comandos dentro del controlador de Spark que se está ejecutando en un POD.</span>\n",
                "\n",
                "> **Nota:** Reemplaza el ID en el Spark-pi-ID-driver con el que has creado tú. Por ejemplo: si tu pod es spark-pi-6f62d17a800beb3e-driver, entonces reemplaza ID con 6f62d17a800beb3e.\n",
                "\n",
                "```bash\n",
                "kubectl logs spark-pi-6f62d17a800beb3e-driver |grep \"Job 0 finished:\"\n",
                "```\n",
                "\n",
                "Deberías obtener algo como:\n",
                "\n",
                "```bash\n",
                "Job 0 finished: reduce at SparkPi.scala:38, took 8.446024 s\n",
                "```\n",
                "\n",
                "Si estás interesado en saber qué valor para _Pi_ generó la aplicación, simplemente emite:\n",
                "\n",
                "> **Nota:** Reemplaza el ID en el Spark-pi-ID-driver con el que tú creaste. Por ejemplo: si tu pod es spark-pi-6f62d17a800beb3e-driver, entonces reemplaza el ID con 6f62d17a800beb3e.\n",
                "\n",
                "```bash\n",
                "kubectl logs spark-pi-6f62d17a800beb3e-driver |grep \"Pi is roughly \"\n",
                "```\n",
                "\n",
                "Y verás algo como:\n",
                "\n",
                "```bash\n",
                "Pi is roughly 3.1416551416551415\n",
                "```"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "7dedfefd-9a47-4295-90c0-6851a848e209"
            },
            "source": [
                "# Experimenta tú mismo\n",
                "\n",
                "Ahora puedes experimentar con valores para _spark.executor.instances_, _spark.kubernetes.executor.limit.cores=0.5_ (0.1 también es un número válido) y el número de iteraciones y ver cómo afecta el tiempo de ejecución y la precisión del resultado. Solo asegúrate de no exceder el límite de cuota de recursos de SkillsNetwork. Observa `Kubectl logs [driver pod]` para verificar los registros por si se excede la cuota.\n",
                "\n",
                "Esto concluye este laboratorio."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "ef3a32a4-6c3b-4a2b-88ff-9f6023ecb9d9"
            },
            "source": [
                "# Resumen\n",
                "\n",
                "En este laboratorio has aprendido a crear un POD cliente de Apache Spark dentro del clúster de Kubernetes para enviar trabajos. Luego, has utilizado el comando spark-submit para crear un trabajo que se ejecuta dentro de este clúster de Kubernetes. Ahora eres capaz de escalar tus trabajos de Apache Spark en cualquier clúster de Kubernetes que se ejecute en la nube o en tu centro de datos a miles de nodos, CPUs y GB de memoria principal."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "SQL",
            "language": "sql",
            "name": "SQL"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
